{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Chromadb locally(to compare model by score)\n",
    "---\n",
    "### RUN ONLY ONCE IF YOU DON'T HAVE DIRECTORY embeddingtest/chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hf_model_names() -> list:\n",
    "    try:\n",
    "        with open(file=\"model/model_list.txt\", mode=\"r\", encoding=\"utf-8\") as file:\n",
    "            model_list = [line.strip() for line in file]\n",
    "    except:\n",
    "        print(\"\"\"file not exsist. check directory or file.\"\"\")\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.chroma import Chroma\n",
    "\n",
    "### from_document method 이용해서 저장(document, embedding, persist_directory, collection_name)\n",
    "#Chroma object 생성.\n",
    "chroma = Chroma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize class takes 0.0 seconds.\n",
      "initialize class takes 0.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:06<00:00,  6.34it/s]\n",
      "100%|██████████| 36/36 [00:00<00:00, 40.12it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 41.51it/s]\n",
      "100%|██████████| 57/57 [00:01<00:00, 43.35it/s]\n",
      "100%|██████████| 27/27 [00:00<00:00, 42.10it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 47.60it/s]\n",
      "100%|██████████| 83/83 [00:01<00:00, 43.68it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 49.64it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 30.00it/s]\n",
      "100%|██████████| 86/86 [00:02<00:00, 42.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Documents takes 16.681987 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/41 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 41/41 [00:00<00:00, 44.53it/s]\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 36/36 [00:00<00:00, 51.14it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 50/50 [00:00<00:00, 60.70it/s]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 57/57 [00:00<00:00, 75.36it/s]\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 27/27 [00:00<00:00, 47.06it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 20/20 [00:00<00:00, 45.31it/s]\n",
      "  0%|          | 0/83 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 83/83 [00:01<00:00, 61.26it/s]\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 40/40 [00:00<00:00, 69.21it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 24/24 [00:00<00:00, 42.74it/s]\n",
      "  0%|          | 0/86 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 86/86 [00:01<00:00, 53.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Documents takes 8.539436 seconds.\n"
     ]
    }
   ],
   "source": [
    "#Pre-load document\n",
    "from document.mdLoader import TeamALoader, TeamBLoader\n",
    "\n",
    "#document parsing when get max_seq_length -> use in chroma.from_documents()\n",
    "#일단 split 없이 진행하고, chroma db에 넣을 때 sequence에 맞춰서 split 해 줄 것(편의성을 위해 미리 불러온다.)\n",
    "a_loader = TeamALoader(path_db=\"data/teamA\", path_metadata=\"document/meta_team_a.json\", path_url_table=\"document/url_table_team_a.csv\", text_splitter=None)\n",
    "b_loader = TeamBLoader(path_db=\"data/teamB\", path_metadata=\"document/meta_team_b.json\", path_url_table=\"document/url_table_team_b.csv\", text_splitter=None)\n",
    "\n",
    "a_raw_docs = a_loader.load(is_split=False, is_regex=False, show_progress=True)\n",
    "b_raw_docs = b_loader.load(is_split=False, is_regex=True, show_progress=True)\n",
    "\n",
    "### splitter 넣어서 하자........... seq 구하고 -> 이건 model loading 필요하니까 결국... loading하고\n",
    "## None으로 시작한 다음에 Splitter 넣어서 돌아가게 하고 다음에 수정해서 하나의 .py로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Model Loading\n",
    "from embedding import EmbeddingLoader\n",
    "\n",
    "ste_embedding = EmbeddingLoader.SentenceTransformerEmbedding\n",
    "openai_embedding = EmbeddingLoader.OpenAIEmbedding\n",
    "\n",
    "# UseCase\n",
    "# ste_embedding()\n",
    "# openai_embedding()\n",
    "\n",
    "# get model names\n",
    "model_list = get_hf_model_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HuggingFace Embedding Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import SentenceTransformersTokenTextSplitter, TokenTextSplitter #STE, OpenAIEmbedding(@text-ada-002)\n",
    "import os\n",
    "import json\n",
    "\n",
    "def set_text_splitter(ste_model, max_seq_length)->SentenceTransformersTokenTextSplitter:\n",
    "    splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=10, model_name=ste_model, tokens_per_chunk=max_seq_length)\n",
    "    return splitter\n",
    "\n",
    "def get_max_seq_length(model_path)->int:\n",
    "    sentence_bert_config = \"sentence_bert_config.json\"\n",
    "    config_path = os.path.join(model_path, sentence_bert_config)\n",
    "\n",
    "    with open(config_path) as file :\n",
    "        bert_config = json.load(file)\n",
    "        \n",
    "    return bert_config[\"max_seq_length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding model in path <model/sentence-transformers/paraphrase-multilingual-mpnet-base-v2> has been loaded successfully.\n",
      "Function call load took 6.275824s to run.\n",
      "\n",
      "max sequence from current model(model/sentence-transformers/paraphrase-multilingual-mpnet-base-v2) is 128.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:1764, B:1307>\n",
      "name='paraphrase-multilingual-mpnet-base-v2-a' id=UUID('e87d2b8f-070d-47a0-afa6-ca0e22fcc07e') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='paraphrase-multilingual-mpnet-base-v2-b' id=UUID('c87ccae0-7ab9-4f04-8663-b1e0f886ce77') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2> has been loaded successfully.\n",
      "Function call load took 2.651525s to run.\n",
      "\n",
      "max sequence from current model(model/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2) is 128.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:1764, B:1307>\n",
      "name='paraphrase-multilingual-MiniLM-L12-v2-a' id=UUID('60fcdfef-fe0e-4de6-bb8d-7da85ab65127') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='paraphrase-multilingual-MiniLM-L12-v2-b' id=UUID('686dd2da-55a5-48b5-9911-c91a135f4639') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/sentence-transformers/distiluse-base-multilingual-cased-v2> has been loaded successfully.\n",
      "Function call load took 2.253743s to run.\n",
      "\n",
      "max sequence from current model(model/sentence-transformers/distiluse-base-multilingual-cased-v2) is 128.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:2170, B:1596>\n",
      "name='distiluse-base-multilingual-cased-v2-a' id=UUID('b9fe2196-197a-4418-9c59-9432746543c7') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='distiluse-base-multilingual-cased-v2-b' id=UUID('54833279-71d5-4590-8dde-2bab76dbd885') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/sentence-transformers/stsb-xlm-r-multilingual> has been loaded successfully.\n",
      "Function call load took 5.451098s to run.\n",
      "\n",
      "max sequence from current model(model/sentence-transformers/stsb-xlm-r-multilingual) is 128.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:1764, B:1307>\n",
      "name='stsb-xlm-r-multilingual-a' id=UUID('8c293ee3-ff41-42f3-b4ff-abfad716fcc3') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='stsb-xlm-r-multilingual-b' id=UUID('6332bc6f-5596-4ea6-9dc3-ecd0384b61d4') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/jhgan/ko-sroberta-multitask> has been loaded successfully.\n",
      "Function call load took 0.938126s to run.\n",
      "\n",
      "max sequence from current model(model/jhgan/ko-sroberta-multitask) is 128.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:1732, B:1250>\n",
      "name='ko-sroberta-multitask-a' id=UUID('08cd1ecb-23de-45a2-aa7f-667fb250b4aa') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='ko-sroberta-multitask-b' id=UUID('6887074b-ffd1-45f6-83e7-39c7d70357b4') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/snunlp/KR-SBERT-V40K-klueNLI-augSTS> has been loaded successfully.\n",
      "Function call load took 1.015001s to run.\n",
      "\n",
      "max sequence from current model(model/snunlp/KR-SBERT-V40K-klueNLI-augSTS) is 128.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:1476, B:1101>\n",
      "name='KR-SBERT-V40K-klueNLI-augSTS-a' id=UUID('122c23f2-a444-42f4-84a8-8d8a439b84cd') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='KR-SBERT-V40K-klueNLI-augSTS-b' id=UUID('a7fe2880-8205-4738-9f68-3c2cc9680906') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/bongsoo/moco-sentencedistilbertV2.1> has been loaded successfully.\n",
      "Function call load took 1.390272s to run.\n",
      "\n",
      "max sequence from current model(model/bongsoo/moco-sentencedistilbertV2.1) is 256.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:868, B:670>\n",
      "name='moco-sentencedistilbertV2.1-a' id=UUID('6e5a82ad-93b5-433d-98ec-8e4bd41b2b5c') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='moco-sentencedistilbertV2.1-b' id=UUID('f7519db1-e15c-4f20-9ba6-aea667b4b459') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/bongsoo/kpf-sbert-128d-v1> has been loaded successfully.\n",
      "Function call load took 1.13539s to run.\n",
      "\n",
      "max sequence from current model(model/bongsoo/kpf-sbert-128d-v1) is 512.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:583, B:512>\n",
      "name='kpf-sbert-128d-v1-a' id=UUID('66946f9a-6af9-4df2-b278-99a5b08f3a93') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='kpf-sbert-128d-v1-b' id=UUID('0ab4de52-0919-4fea-9c25-2c9be615a2ad') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/M-CLIP/M-BERT-Distil-40> has been loaded successfully.\n",
      "Function call load took 1.177555s to run.\n",
      "\n",
      "max sequence from current model(model/M-CLIP/M-BERT-Distil-40) is 512.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:673, B:569>\n",
      "name='M-BERT-Distil-40-a' id=UUID('60a482b3-6126-4c5e-b81c-6f9c332de630') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='M-BERT-Distil-40-b' id=UUID('1803d729-b84b-49c5-bd24-69ad74685105') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/google/canine-c> has been loaded successfully.\n",
      "Function call load took 1.461542s to run.\n",
      "\n",
      "max sequence from current model(model/google/canine-c) is 2048.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:482, B:473>\n",
      "name='canine-c-a' id=UUID('46cd620f-291c-429f-8ff9-bbf5f4751c49') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='canine-c-b' id=UUID('ea0ea66a-5cee-4a9e-92fe-505896767ee3') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/smartmind/roberta-ko-small-tsdae> has been loaded successfully.\n",
      "Function call load took 0.593759s to run.\n",
      "\n",
      "max sequence from current model(model/smartmind/roberta-ko-small-tsdae) is 508.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:544, B:516>\n",
      "name='roberta-ko-small-tsdae-a' id=UUID('eb335149-abb0-4d1c-a6a8-10a4af69cb03') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='roberta-ko-small-tsdae-b' id=UUID('9ee9afaa-6c0c-40fc-a753-fd7a011b5f5a') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/BM-K/KoSimCSE-roberta-multitask> has been loaded successfully.\n",
      "Function call load took 1.894729s to run.\n",
      "\n",
      "max sequence from current model(model/BM-K/KoSimCSE-roberta-multitask) is 512.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:588, B:513>\n",
      "name='KoSimCSE-roberta-multitask-a' id=UUID('1e724035-acde-49e0-ba00-5c08ac43d918') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='KoSimCSE-roberta-multitask-b' id=UUID('10738c61-ed39-489c-aeb1-77387b1489e0') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## HuggingFaceEmbedding Setup\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "directory = \"model/\"\n",
    "sentence_bert_config = \"sentence_bert_config.json\"\n",
    "\n",
    "for model in model_list:\n",
    "    # load model from locally saved HuggingFace model\n",
    "    model_path = os.path.join(directory, model)\n",
    "    \n",
    "    sentenceloader = ste_embedding(model_name=model_path, multi_process=True, encode_kwargs={'normalize_embeddings':True})\n",
    "    embedding_model = sentenceloader.load()\n",
    "\n",
    "    max_seq_length = get_max_seq_length(model_path=model_path)\n",
    "    text_splitter = set_text_splitter(model_path, max_seq_length=max_seq_length)\n",
    "\n",
    "    a_splitted_docs = text_splitter.split_documents(a_raw_docs)\n",
    "    b_splitted_docs = text_splitter.split_documents(b_raw_docs)\n",
    "\n",
    "    # get max sequence length from embedding model\n",
    "    config_path = os.path.join(model_path, sentence_bert_config)\n",
    "    with open(config_path) as file :\n",
    "        bert_config = json.load(file)\n",
    "        max_seq_length = bert_config[\"max_seq_length\"]\n",
    "\n",
    "    print(f\"max sequence from current model({model_path}) is {max_seq_length}.\")\n",
    "\n",
    "    print(f\"Document splitted with SentenceTransformerTokenizer -> length <A:{len(a_splitted_docs)}, B:{len(b_splitted_docs)}>\")\n",
    "\n",
    "    # set model name(cause collection name length limit)\n",
    "    model_name = model.split(\"/\")[-1]\n",
    "\n",
    "    # save document with chunk - embedding calculate and save it to persist directory\n",
    "    collection_a = chroma.from_documents(documents=a_splitted_docs, embedding=embedding_model, collection_name=model_name+\"-a\", collection_metadata={\"hnsw:space\":\"cosine\"}, persist_directory=\"chroma\")\n",
    "    collection_a.persist()\n",
    "    print(collection_a._collection)\n",
    "\n",
    "    collection_b = chroma.from_documents(documents=b_splitted_docs, embedding=embedding_model, collection_name=model_name+\"-b\", collection_metadata={\"hnsw:space\":\"cosine\"}, persist_directory=\"chroma\")\n",
    "    collection_b.persist()\n",
    "    print(collection_b._collection)\n",
    "\n",
    "    print(\"=\"*60, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenAI Embedding Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI Embedding has been activated.\n",
      "Function call load took 0.0s to run.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:01<00:00, 36.87it/s]\n",
      "100%|██████████| 36/36 [00:00<00:00, 41.84it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 42.85it/s]\n",
      "100%|██████████| 57/57 [00:01<00:00, 42.75it/s]\n",
      "100%|██████████| 27/27 [00:00<00:00, 44.25it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 46.64it/s]\n",
      "100%|██████████| 83/83 [00:01<00:00, 44.14it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 50.05it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 32.17it/s]\n",
      "100%|██████████| 86/86 [00:02<00:00, 41.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Documents takes 11.480287 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/41 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 41/41 [00:00<00:00, 44.92it/s]\n",
      " 11%|█         | 4/36 [00:00<00:00, 37.56it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 36/36 [00:00<00:00, 50.76it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 50/50 [00:00<00:00, 59.34it/s]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 57/57 [00:00<00:00, 74.18it/s]\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 27/27 [00:00<00:00, 46.65it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 20/20 [00:00<00:00, 45.48it/s]\n",
      "  0%|          | 0/83 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 83/83 [00:01<00:00, 61.28it/s]\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 40/40 [00:00<00:00, 67.60it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 24/24 [00:00<00:00, 41.48it/s]\n",
      "  0%|          | 0/86 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 86/86 [00:01<00:00, 54.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Documents takes 8.747674 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.chroma.Chroma at 0x1cc2f239d50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = openai_embedding()\n",
    "emb_openai = loader.load()\n",
    "\n",
    "openai_text_splitter = TokenTextSplitter.from_tiktoken_encoder(\n",
    "    model_name=emb_openai.model\n",
    ")\n",
    "\n",
    "a_loader.text_splitter = openai_text_splitter\n",
    "b_loader.text_splitter = openai_text_splitter\n",
    "\n",
    "a_raw_docs = a_loader.load(is_split=True, is_regex=False)\n",
    "b_raw_docs = b_loader.load(is_split=True, is_regex=True)\n",
    "\n",
    "chroma.from_documents(documents=a_raw_docs, embedding=emb_openai, collection_name=emb_openai.model+\"-a\", collection_metadata={\"hnsw:space\":\"cosine\"}, persist_directory=\"chroma\")\n",
    "chroma.from_documents(documents=b_raw_docs, embedding=emb_openai, collection_name=emb_openai.model+\"-b\", collection_metadata={\"hnsw:space\":\"cosine\"}, persist_directory=\"chroma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
