{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Chromadb locally(to compare model by score)\n",
    "---\n",
    "### RUN ONLY ONCE IF YOU DON'T HAVE DIRECTORY embeddingtest/chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hf_model_names() -> list:\n",
    "    try:\n",
    "        with open(file=\"model/model_list.txt\", mode=\"r\", encoding=\"utf-8\") as file:\n",
    "            model_list = [line.strip() for line in file]\n",
    "    except:\n",
    "        print(\"\"\"file not exsist. check directory or file.\"\"\")\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.chroma import Chroma\n",
    "\n",
    "### from_document method 이용해서 저장(document, embedding, persist_directory, collection_name)\n",
    "#Chroma object 생성.\n",
    "chroma = Chroma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize class takes 0.0 seconds.\n",
      "initialize class takes 0.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:05<00:00,  7.31it/s]\n",
      "100%|██████████| 36/36 [00:00<00:00, 40.79it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 42.12it/s]\n",
      "100%|██████████| 57/57 [00:01<00:00, 37.18it/s]\n",
      "100%|██████████| 27/27 [00:00<00:00, 41.98it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 45.49it/s]\n",
      "100%|██████████| 83/83 [00:01<00:00, 42.88it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 49.27it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 42.53it/s]\n",
      "100%|██████████| 86/86 [00:02<00:00, 41.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Documents takes 15.941847 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 4/41 [00:00<00:00, 38.94it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 41/41 [00:00<00:00, 42.92it/s]\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 36/36 [00:00<00:00, 49.71it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 50/50 [00:00<00:00, 57.47it/s]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 57/57 [00:00<00:00, 67.80it/s]\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 27/27 [00:00<00:00, 45.25it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 20/20 [00:00<00:00, 39.93it/s]\n",
      "  0%|          | 0/83 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 83/83 [00:01<00:00, 57.45it/s]\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 40/40 [00:00<00:00, 63.65it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 24/24 [00:00<00:00, 39.61it/s]\n",
      "  0%|          | 0/86 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 86/86 [00:01<00:00, 51.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Documents takes 9.086778 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Pre-load document\n",
    "from document.mdLoader import TeamALoader, TeamBLoader\n",
    "\n",
    "#document parsing when get max_seq_length -> use in chroma.from_documents()\n",
    "#일단 split 없이 진행하고, chroma db에 넣을 때 sequence에 맞춰서 split 해 줄 것(편의성을 위해 미리 불러온다.)\n",
    "a_loader = TeamALoader(path_db=\"data/teamA\", path_metadata=\"document/meta_team_a.json\", path_url_table=\"document/url_table_team_a.csv\", text_splitter=None)\n",
    "b_loader = TeamBLoader(path_db=\"data/teamB\", path_metadata=\"document/meta_team_b.json\", path_url_table=\"document/url_table_team_b.csv\", text_splitter=None)\n",
    "\n",
    "a_raw_docs = a_loader.load(is_split=False, is_regex=False, show_progress=True)\n",
    "b_raw_docs = b_loader.load(is_split=False, is_regex=True, show_progress=True)\n",
    "\n",
    "### splitter 넣어서 하자........... seq 구하고 -> 이건 model loading 필요하니까 결국... loading하고\n",
    "## None으로 시작한 다음에 Splitter 넣어서 돌아가게 하고 다음에 수정해서 하나의 .py로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Model Loading\n",
    "from embedding import EmbeddingLoader\n",
    "\n",
    "ste_embedding = EmbeddingLoader.SentenceTransformerEmbedding\n",
    "openai_embedding = EmbeddingLoader.OpenAIEmbedding\n",
    "\n",
    "# UseCase\n",
    "# ste_embedding()\n",
    "# openai_embedding()\n",
    "\n",
    "# get model names\n",
    "model_list = get_hf_model_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HuggingFace Embedding Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import SentenceTransformersTokenTextSplitter, TokenTextSplitter #STE, OpenAIEmbedding(@text-ada-002)\n",
    "import os\n",
    "import json\n",
    "\n",
    "def set_text_splitter(ste_model, max_seq_length)->SentenceTransformersTokenTextSplitter:\n",
    "    splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=10, model_name=ste_model, tokens_per_chunk=max_seq_length)\n",
    "    return splitter\n",
    "\n",
    "def get_max_seq_length(model_path)->int:\n",
    "    sentence_bert_config = \"sentence_bert_config.json\"\n",
    "    config_path = os.path.join(model_path, sentence_bert_config)\n",
    "\n",
    "    with open(config_path) as file :\n",
    "        bert_config = json.load(file)\n",
    "        \n",
    "    return bert_config[\"max_seq_length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding model in path <model/sentence-transformers/paraphrase-multilingual-mpnet-base-v2> has been loaded successfully.\n",
      "Function call load took 4.888586s to run.\n",
      "\n",
      "max sequence from current model(model/sentence-transformers/paraphrase-multilingual-mpnet-base-v2) is 128.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:1782, B:1307>\n",
      "name='paraphrase-multilingual-mpnet-base-v2-a' id=UUID('02f482bf-1717-4e6c-98a4-af61adc61999') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='paraphrase-multilingual-mpnet-base-v2-b' id=UUID('795c7e3d-61ec-4788-8a64-4d901a64675b') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2> has been loaded successfully.\n",
      "Function call load took 1.787393s to run.\n",
      "\n",
      "max sequence from current model(model/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2) is 128.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:1782, B:1307>\n",
      "name='paraphrase-multilingual-MiniLM-L12-v2-a' id=UUID('eadd5e36-496b-428e-8555-6db1bf87477b') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='paraphrase-multilingual-MiniLM-L12-v2-b' id=UUID('4930f1c8-42d9-4e02-a181-ad38dcf6209c') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/sentence-transformers/distiluse-base-multilingual-cased-v2> has been loaded successfully.\n",
      "Function call load took 1.215664s to run.\n",
      "\n",
      "max sequence from current model(model/sentence-transformers/distiluse-base-multilingual-cased-v2) is 128.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:2190, B:1596>\n",
      "name='distiluse-base-multilingual-cased-v2-a' id=UUID('95d257b4-0177-4e96-8f38-f22cd434379d') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='distiluse-base-multilingual-cased-v2-b' id=UUID('2e2d02ec-9324-407f-a2fc-d015fe20a370') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/sentence-transformers/stsb-xlm-r-multilingual> has been loaded successfully.\n",
      "Function call load took 2.993966s to run.\n",
      "\n",
      "max sequence from current model(model/sentence-transformers/stsb-xlm-r-multilingual) is 128.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:1782, B:1307>\n",
      "name='stsb-xlm-r-multilingual-a' id=UUID('ccb32ca1-1683-4786-b11b-57c063b1b2e0') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='stsb-xlm-r-multilingual-b' id=UUID('3c962d44-0bfa-4599-8a8c-ef7ea21c280b') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/jhgan/ko-sroberta-multitask> has been loaded successfully.\n",
      "Function call load took 1.027828s to run.\n",
      "\n",
      "max sequence from current model(model/jhgan/ko-sroberta-multitask) is 128.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:1751, B:1250>\n",
      "name='ko-sroberta-multitask-a' id=UUID('8ab93abf-479f-411d-99a3-5ae0bf5f9637') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='ko-sroberta-multitask-b' id=UUID('6757603f-2676-4ae3-b255-b01b1c1edd6a') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/snunlp/KR-SBERT-V40K-klueNLI-augSTS> has been loaded successfully.\n",
      "Function call load took 1.120001s to run.\n",
      "\n",
      "max sequence from current model(model/snunlp/KR-SBERT-V40K-klueNLI-augSTS) is 128.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:1493, B:1101>\n",
      "name='KR-SBERT-V40K-klueNLI-augSTS-a' id=UUID('1ede87cf-34b3-4aea-aa0c-cf8c8988b87c') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='KR-SBERT-V40K-klueNLI-augSTS-b' id=UUID('1a1aad6e-7a7a-4f9b-99cc-bba42172c26e') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/bongsoo/moco-sentencedistilbertV2.1> has been loaded successfully.\n",
      "Function call load took 1.438257s to run.\n",
      "\n",
      "max sequence from current model(model/bongsoo/moco-sentencedistilbertV2.1) is 256.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:872, B:670>\n",
      "name='moco-sentencedistilbertV2.1-a' id=UUID('e38ec77a-0355-481b-8743-88187e10060d') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='moco-sentencedistilbertV2.1-b' id=UUID('50e2475a-f605-4e4a-b0ac-85ed77b80d0c') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/bongsoo/kpf-sbert-128d-v1> has been loaded successfully.\n",
      "Function call load took 0.967431s to run.\n",
      "\n",
      "max sequence from current model(model/bongsoo/kpf-sbert-128d-v1) is 512.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:584, B:512>\n",
      "name='kpf-sbert-128d-v1-a' id=UUID('55d3d2b1-f95a-4ce4-bdf5-80d3c6c309f1') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='kpf-sbert-128d-v1-b' id=UUID('3b51e6af-e4cf-45a5-b2eb-4a97286c5682') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/M-CLIP/M-BERT-Distil-40> has been loaded successfully.\n",
      "Function call load took 1.169966s to run.\n",
      "\n",
      "max sequence from current model(model/M-CLIP/M-BERT-Distil-40) is 512.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:684, B:569>\n",
      "name='M-BERT-Distil-40-a' id=UUID('02b00822-927e-4beb-9eff-e2ef5bada9a4') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='M-BERT-Distil-40-b' id=UUID('fdaa523d-a410-4b9d-ae25-9bdc7f976668') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/google/canine-c> has been loaded successfully.\n",
      "Function call load took 1.611001s to run.\n",
      "\n",
      "max sequence from current model(model/google/canine-c) is 2048.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:483, B:473>\n",
      "name='canine-c-a' id=UUID('02b1107d-5f27-4af1-a4ce-63a4b8c20061') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='canine-c-b' id=UUID('59f509ce-4ad8-48f2-b92d-c81bf14662a2') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/smartmind/roberta-ko-small-tsdae> has been loaded successfully.\n",
      "Function call load took 0.624712s to run.\n",
      "\n",
      "max sequence from current model(model/smartmind/roberta-ko-small-tsdae) is 508.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:545, B:516>\n",
      "name='roberta-ko-small-tsdae-a' id=UUID('c4cae20b-4d26-4a17-931a-c051952f2c11') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='roberta-ko-small-tsdae-b' id=UUID('66732f99-387b-47cf-841b-d1c230ef0c22') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/BM-K/KoSimCSE-roberta-multitask> has been loaded successfully.\n",
      "Function call load took 1.934937s to run.\n",
      "\n",
      "max sequence from current model(model/BM-K/KoSimCSE-roberta-multitask) is 512.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:589, B:513>\n",
      "name='KoSimCSE-roberta-multitask-a' id=UUID('742a26e9-6d8f-460d-bf6c-73d537133b95') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='KoSimCSE-roberta-multitask-b' id=UUID('0113c6be-b85e-445a-b90f-0c6d5ae5fda1') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## HuggingFaceEmbedding Setup\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "directory = \"model/\"\n",
    "sentence_bert_config = \"sentence_bert_config.json\"\n",
    "\n",
    "for model in model_list:\n",
    "    # load model from locally saved HuggingFace model\n",
    "    model_path = os.path.join(directory, model)\n",
    "    \n",
    "    sentenceloader = ste_embedding(model_name=model_path, multi_process=True, encode_kwargs={'normalize_embeddings':True})\n",
    "    embedding_model = sentenceloader.load()\n",
    "\n",
    "    max_seq_length = get_max_seq_length(model_path=model_path)\n",
    "    text_splitter = set_text_splitter(model_path, max_seq_length=max_seq_length)\n",
    "\n",
    "    a_splitted_docs = text_splitter.split_documents(a_raw_docs)\n",
    "    b_splitted_docs = text_splitter.split_documents(b_raw_docs)\n",
    "\n",
    "    # get max sequence length from embedding model\n",
    "    config_path = os.path.join(model_path, sentence_bert_config)\n",
    "    with open(config_path) as file :\n",
    "        bert_config = json.load(file)\n",
    "        max_seq_length = bert_config[\"max_seq_length\"]\n",
    "\n",
    "    print(f\"max sequence from current model({model_path}) is {max_seq_length}.\")\n",
    "\n",
    "    print(f\"Document splitted with SentenceTransformerTokenizer -> length <A:{len(a_splitted_docs)}, B:{len(b_splitted_docs)}>\")\n",
    "\n",
    "    # set model name(cause collection name length limit)\n",
    "    model_name = model.split(\"/\")[-1]\n",
    "\n",
    "    # save document with chunk - embedding calculate and save it to persist directory\n",
    "    collection_a = chroma.from_documents(documents=a_splitted_docs, embedding=embedding_model, collection_name=model_name+\"-a\", collection_metadata={\"hnsw:space\":\"cosine\"}, persist_directory=\"chroma\")\n",
    "    collection_a.persist()\n",
    "    print(collection_a._collection)\n",
    "\n",
    "    collection_b = chroma.from_documents(documents=b_splitted_docs, embedding=embedding_model, collection_name=model_name+\"-b\", collection_metadata={\"hnsw:space\":\"cosine\"}, persist_directory=\"chroma\")\n",
    "    collection_b.persist()\n",
    "    print(collection_b._collection)\n",
    "\n",
    "    print(\"=\"*60, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenAI Embedding Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI Embedding has been activated.\n",
      "Function call load took 0.0s to run.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:01<00:00, 34.16it/s]\n",
      "100%|██████████| 36/36 [00:00<00:00, 38.49it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 40.70it/s]\n",
      "100%|██████████| 57/57 [00:01<00:00, 38.27it/s]\n",
      "100%|██████████| 27/27 [00:00<00:00, 38.75it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 39.59it/s]\n",
      "100%|██████████| 83/83 [00:02<00:00, 39.03it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 46.50it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 43.11it/s]\n",
      "100%|██████████| 86/86 [00:02<00:00, 41.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Documents takes 12.18189 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/41 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 41/41 [00:00<00:00, 43.03it/s]\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 36/36 [00:00<00:00, 48.75it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 50/50 [00:00<00:00, 57.32it/s]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 57/57 [00:00<00:00, 72.63it/s]\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 27/27 [00:00<00:00, 45.97it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 20/20 [00:00<00:00, 44.62it/s]\n",
      "  0%|          | 0/83 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 83/83 [00:01<00:00, 59.02it/s]\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 40/40 [00:00<00:00, 49.30it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 24/24 [00:00<00:00, 41.56it/s]\n",
      "  0%|          | 0/86 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 86/86 [00:01<00:00, 51.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Documents takes 9.260814 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x15d2891b040>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = openai_embedding()\n",
    "emb_openai = loader.load()\n",
    "\n",
    "openai_text_splitter = TokenTextSplitter.from_tiktoken_encoder(\n",
    "    model_name=emb_openai.model\n",
    ")\n",
    "\n",
    "a_loader.text_splitter = openai_text_splitter\n",
    "b_loader.text_splitter = openai_text_splitter\n",
    "\n",
    "a_raw_docs = a_loader.load(is_split=True, is_regex=False)\n",
    "b_raw_docs = b_loader.load(is_split=True, is_regex=True)\n",
    "\n",
    "chroma.from_documents(documents=a_raw_docs, embedding=emb_openai, collection_name=emb_openai.model+\"-a\", collection_metadata={\"hnsw:space\":\"cosine\"}, persist_directory=\"chroma\")\n",
    "chroma.from_documents(documents=b_raw_docs, embedding=emb_openai, collection_name=emb_openai.model+\"-b\", collection_metadata={\"hnsw:space\":\"cosine\"}, persist_directory=\"chroma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
