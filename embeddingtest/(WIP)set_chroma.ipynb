{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Chromadb locally(to compare model by score)\n",
    "---\n",
    "### RUN ONLY ONCE IF YOU DON'T HAVE DIRECTORY embeddingtest/chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hf_model_names() -> list:\n",
    "    try:\n",
    "        with open(file=\"model/model_list.txt\", mode=\"r\", encoding=\"utf-8\") as file:\n",
    "            model_list = [line.strip() for line in file]\n",
    "    except:\n",
    "        print(\"\"\"file not exsist. check directory or file.\"\"\")\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.chroma import Chroma\n",
    "\n",
    "### from_document method 이용해서 저장(document, embedding, persist_directory, collection_name)\n",
    "#Chroma object 생성.\n",
    "chroma = Chroma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize class takes 0.0 seconds.\n",
      "initialize class takes 0.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:05<00:00,  7.51it/s]\n",
      "100%|██████████| 36/36 [00:00<00:00, 40.01it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 40.55it/s]\n",
      "100%|██████████| 57/57 [00:01<00:00, 40.75it/s]\n",
      "100%|██████████| 27/27 [00:00<00:00, 38.68it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 40.52it/s]\n",
      "100%|██████████| 83/83 [00:02<00:00, 38.01it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 46.29it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 29.38it/s]\n",
      "100%|██████████| 86/86 [00:02<00:00, 40.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Documents takes 16.406961 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/41 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 41/41 [00:00<00:00, 41.07it/s]\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 36/36 [00:00<00:00, 46.21it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 50/50 [00:00<00:00, 54.30it/s]\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 57/57 [00:00<00:00, 65.76it/s]\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 27/27 [00:00<00:00, 43.49it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 20/20 [00:00<00:00, 42.07it/s]\n",
      "  0%|          | 0/83 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 83/83 [00:01<00:00, 56.25it/s]\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 40/40 [00:00<00:00, 62.01it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 24/24 [00:00<00:00, 38.66it/s]\n",
      "  0%|          | 0/86 [00:00<?, ?it/s]c:\\anaconda\\envs\\py3.10.13\\lib\\site-packages\\unstructured\\documents\\html.py:498: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  rows = body.findall(\"tr\") if body else []\n",
      "100%|██████████| 86/86 [00:01<00:00, 49.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Documents takes 9.38866 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Pre-load document\n",
    "from document.mdLoader import TeamALoader, TeamBLoader\n",
    "\n",
    "#document parsing when get max_seq_length -> use in chroma.from_documents()\n",
    "#일단 split 없이 진행하고, chroma db에 넣을 때 sequence에 맞춰서 split 해 줄 것(편의성을 위해 미리 불러온다.)\n",
    "a_loader = TeamALoader(path_db=\"data/teamA\", path_metadata=\"document/meta_team_a.json\", path_url_table=\"document/url_table_team_a.csv\", text_splitter=None)\n",
    "b_loader = TeamBLoader(path_db=\"data/teamB\", path_metadata=\"document/meta_team_b.json\", path_url_table=\"document/url_table_team_b.csv\", text_splitter=None)\n",
    "\n",
    "a_raw_docs = a_loader.load(is_split=False, is_regex=False, show_progress=True)\n",
    "b_raw_docs = b_loader.load(is_split=False, is_regex=True, show_progress=True)\n",
    "\n",
    "### splitter 넣어서 하자........... seq 구하고 -> 이건 model loading 필요하니까 결국... loading하고\n",
    "## None으로 시작한 다음에 Splitter 넣어서 돌아가게 하고 다음에 수정해서 하나의 .py로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Model Loading\n",
    "from embedding import EmbeddingLoader\n",
    "\n",
    "ste_embedding = EmbeddingLoader.SentenceTransformerEmbedding\n",
    "openai_embedding = EmbeddingLoader.OpenAIEmbedding\n",
    "\n",
    "# UseCase\n",
    "# ste_embedding()\n",
    "# openai_embedding()\n",
    "\n",
    "# get model names\n",
    "model_list = get_hf_model_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HuggingFace Embedding Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import SentenceTransformersTokenTextSplitter, TokenTextSplitter #STE, OpenAIEmbedding(@text-ada-002)\n",
    "import os\n",
    "import json\n",
    "\n",
    "def set_text_splitter(ste_model, max_seq_length)->SentenceTransformersTokenTextSplitter:\n",
    "    splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=10, model_name=ste_model, tokens_per_chunk=max_seq_length)\n",
    "    return splitter\n",
    "\n",
    "def get_max_seq_length(model_path)->int:\n",
    "    sentence_bert_config = \"sentence_bert_config.json\"\n",
    "    config_path = os.path.join(model_path, sentence_bert_config)\n",
    "\n",
    "    with open(config_path) as file :\n",
    "        bert_config = json.load(file)\n",
    "        \n",
    "    return bert_config[\"max_seq_length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding model in path <model/sentence-transformers/paraphrase-multilingual-mpnet-base-v2> has been loaded successfully.\n",
      "Function call load took 3.910045s to run.\n",
      "\n",
      "max sequence from current model(model/sentence-transformers/paraphrase-multilingual-mpnet-base-v2) is 128.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:1764, B:1307>\n",
      "name='paraphrase-multilingual-mpnet-base-v2-a' id=UUID('661b1876-9c14-46e1-b9ed-c4517e723270') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='paraphrase-multilingual-mpnet-base-v2-b' id=UUID('9744c008-ac10-4a40-9f84-94e6e803b08f') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2> has been loaded successfully.\n",
      "Function call load took 1.657217s to run.\n",
      "\n",
      "max sequence from current model(model/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2) is 128.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:1764, B:1307>\n",
      "name='paraphrase-multilingual-MiniLM-L12-v2-a' id=UUID('5e0b41ac-23c1-4da8-99bb-467e9c3503bc') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='paraphrase-multilingual-MiniLM-L12-v2-b' id=UUID('ac788ec2-cdd0-43c7-a3f7-1ac95054abd3') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/sentence-transformers/distiluse-base-multilingual-cased-v2> has been loaded successfully.\n",
      "Function call load took 1.177095s to run.\n",
      "\n",
      "max sequence from current model(model/sentence-transformers/distiluse-base-multilingual-cased-v2) is 128.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:2170, B:1596>\n",
      "name='distiluse-base-multilingual-cased-v2-a' id=UUID('c0cf6eea-f342-4674-b852-b6a3705b8479') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='distiluse-base-multilingual-cased-v2-b' id=UUID('495653dc-1c4a-4954-a15a-a5a5228ce1f8') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/sentence-transformers/stsb-xlm-r-multilingual> has been loaded successfully.\n",
      "Function call load took 3.021475s to run.\n",
      "\n",
      "max sequence from current model(model/sentence-transformers/stsb-xlm-r-multilingual) is 128.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:1764, B:1307>\n",
      "name='stsb-xlm-r-multilingual-a' id=UUID('d58e544d-b894-4cd6-9293-33e6b6c2f44d') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='stsb-xlm-r-multilingual-b' id=UUID('0f3aa26e-e95e-4b3d-a49d-7a062b820b47') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/jhgan/ko-sroberta-multitask> has been loaded successfully.\n",
      "Function call load took 0.974564s to run.\n",
      "\n",
      "max sequence from current model(model/jhgan/ko-sroberta-multitask) is 128.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:1732, B:1250>\n",
      "name='ko-sroberta-multitask-a' id=UUID('06efa3c6-2007-44f4-a9f6-25ebd5472908') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='ko-sroberta-multitask-b' id=UUID('7e620160-afd6-44a3-985c-beb4b124e2a6') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/snunlp/KR-SBERT-V40K-klueNLI-augSTS> has been loaded successfully.\n",
      "Function call load took 0.958702s to run.\n",
      "\n",
      "max sequence from current model(model/snunlp/KR-SBERT-V40K-klueNLI-augSTS) is 128.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:1476, B:1101>\n",
      "name='KR-SBERT-V40K-klueNLI-augSTS-a' id=UUID('1a193143-a4bd-49de-a4d2-c27cc89c289e') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='KR-SBERT-V40K-klueNLI-augSTS-b' id=UUID('ada67854-7e80-4746-b978-ebc4362c1842') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/bongsoo/moco-sentencedistilbertV2.1> has been loaded successfully.\n",
      "Function call load took 2.791376s to run.\n",
      "\n",
      "max sequence from current model(model/bongsoo/moco-sentencedistilbertV2.1) is 256.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:868, B:670>\n",
      "name='moco-sentencedistilbertV2.1-a' id=UUID('f08e4c7f-e466-46d5-9075-49270a92643b') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='moco-sentencedistilbertV2.1-b' id=UUID('cbcc3827-83d3-4996-94cf-3d0f4453a67d') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/bongsoo/kpf-sbert-128d-v1> has been loaded successfully.\n",
      "Function call load took 1.964754s to run.\n",
      "\n",
      "max sequence from current model(model/bongsoo/kpf-sbert-128d-v1) is 512.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:583, B:512>\n",
      "name='kpf-sbert-128d-v1-a' id=UUID('a7c71edc-5ade-46b1-a7c6-1e1313dce305') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "name='kpf-sbert-128d-v1-b' id=UUID('2292f131-c2f5-467e-bc09-ea44ff608cf4') metadata={'hnsw:space': 'cosine'} tenant='default_tenant' database='default_database'\n",
      "============================================================ \n",
      "\n",
      "embedding model in path <model/Huffon/sentence-klue-roberta-base> has been loaded successfully.\n",
      "Function call load took 1.957428s to run.\n",
      "\n",
      "max sequence from current model(model/Huffon/sentence-klue-roberta-base) is 512.\n",
      "Document splitted with SentenceTransformerTokenizer -> length <A:588, B:513>\n"
     ]
    }
   ],
   "source": [
    "## HuggingFaceEmbedding Setup\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "directory = \"model/\"\n",
    "sentence_bert_config = \"sentence_bert_config.json\"\n",
    "\n",
    "for model in model_list:\n",
    "    # load model from locally saved HuggingFace model\n",
    "    model_path = os.path.join(directory, model)\n",
    "    \n",
    "    sentenceloader = ste_embedding(model_name=model_path, multi_process=True, encode_kwargs={'normalize_embeddings':True})\n",
    "    embedding_model = sentenceloader.load()\n",
    "\n",
    "    max_seq_length = get_max_seq_length(model_path=model_path)\n",
    "    text_splitter = set_text_splitter(model_path, max_seq_length=max_seq_length)\n",
    "\n",
    "    a_splitted_docs = text_splitter.split_documents(a_raw_docs)\n",
    "    b_splitted_docs = text_splitter.split_documents(b_raw_docs)\n",
    "\n",
    "    \n",
    "\n",
    "    # get max sequence length from embedding model\n",
    "    config_path = os.path.join(model_path, sentence_bert_config)\n",
    "    with open(config_path) as file :\n",
    "        bert_config = json.load(file)\n",
    "        max_seq_length = bert_config[\"max_seq_length\"]\n",
    "\n",
    "    print(f\"max sequence from current model({model_path}) is {max_seq_length}.\")\n",
    "\n",
    "    print(f\"Document splitted with SentenceTransformerTokenizer -> length <A:{len(a_splitted_docs)}, B:{len(b_splitted_docs)}>\")\n",
    "\n",
    "    # set model name(cause collection name length limit)\n",
    "    model_name = model.split(\"/\")[-1]\n",
    "\n",
    "    # save document with chunk - embedding calculate and save it to persist directory\n",
    "    collection_a = chroma.from_documents(documents=a_raw_docs, embedding=embedding_model, collection_name=model_name+\"-a\", collection_metadata={\"hnsw:space\":\"cosine\"}, persist_directory=\"chroma\")\n",
    "    collection_a.persist()\n",
    "    print(collection_a._collection)\n",
    "\n",
    "    collection_b = chroma.from_documents(documents=b_raw_docs, embedding=embedding_model, collection_name=model_name+\"-b\", collection_metadata={\"hnsw:space\":\"cosine\"}, persist_directory=\"chroma\")\n",
    "    collection_b.persist()\n",
    "    print(collection_b._collection)\n",
    "\n",
    "    print(\"=\"*60, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenAI Embedding Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI Embedding has been activated.\n",
      "Function call load took 0.0s to run.\n",
      "\n",
      "<langchain.text_splitter.TokenTextSplitter object at 0x0000017CD7ED8880>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = openai_embedding()\n",
    "emb_openai = loader.load()\n",
    "\n",
    "openai_text_splitter = TokenTextSplitter.from_tiktoken_encoder(\n",
    "    model_name=emb_openai.model\n",
    ")\n",
    "\n",
    "a_loader.text_splitter = openai_text_splitter\n",
    "b_loader.text_splitter = openai_text_splitter\n",
    "\n",
    "a_raw_docs = a_loader.load(is_split=True, is_regex=False)\n",
    "b_raw_docs = b_loader.load(is_split=True, is_regex=True)\n",
    "\n",
    "chroma.from_documents(documents=a_raw_docs, embedding=emb_openai, collection_name=emb_openai.model+\"-a\", collection_metadata={\"hnsw:space\":\"cosine\"}, persist_directory=\"chroma\")\n",
    "chroma.from_documents(documents=b_raw_docs, embedding=emb_openai, collection_name=emb_openai.model+\"-b\", collection_metadata={\"hnsw:space\":\"cosine\"}, persist_directory=\"chroma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
